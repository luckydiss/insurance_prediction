Проект по прогнозированию размера страховой премии (того сколько клиент заплатит за страховку) на основе сгенерированного датасета с Kaggle: Regression with an Insurance Dataset
([https://www.kaggle.com/datasets/kartik2112/fraud-detection/data](https://www.kaggle.com/competitions/playground-series-s4e12))

- Постановка задачи. Необходимо спрогнозировать, сколько клиент заплатит за страховку (размер страховой премии, Premium Amount). Даны следующие признаки:
    Возраст (Age) — возраст клиента.
    
    Пол (Gender) — пол клиента.
    
    Годовой доход (Annual_Income) — доход клиента в год.
    
    Семейное положение (Marital_Status) — статус в браке.
    
    Количество иждивенцев (Number_of_Dependents) — число лиц, находящихся на иждивении.
    
    Уровень образования (Education_Level).
    
    Род деятельности (Occupation).
    
    Индекс здоровья (Health_Score).
    
    Местоположение (Location).
    
    Тип страхового полиса (Policy_Type).
    
    Количество предыдущих страховых случаев (Previous_Claims).
    
    Возраст автомобиля (Vehicle_Age).
    
    Кредитный рейтинг (Credit_Score).
    
    Срок действия страховки (Insurance_Duration).
    
    Дата начала полиса (Policy_Start_Date).
    
    Отзывы клиентов (Customer_Feedback).
    
    Статус курения (Smoking_Status).
    
    Частота физических упражнений (Exercise_Frequency).

    Тип собственности (Property_Type).
  
- EDA:
-   1. Первым делом, следует отметить что распределение таргета сильно ассиметричное, поэтому необходимо его логарифмировать (в связи с чем при обучении моделей оптимизируется RMSLE).
    2. В данных присутствовали пропуски, например нет информации о предыдущих страховых случаях и роде деятельности (по 30% пропусков) и т.п. Для численных признаков они заменялись медианой, а для категориальных введена отдельная категория "Unknown".
    3. Категория с датой разделена на 3 столбца: день, месяц, год
    4. При анализе корреляционной матрицы, следует вывод, что линейной зависимости между признакам не наблюдается
    5. При анализе распределений численных признаков, следует вывод о том, что переменная Age и Vehicle_Age распределены равномерно, Annual_Income (годовой доход) сильно ассиметрично, Health_Score и Credit_Score почти нормально. Боксплоты показали выбросы в признаке Annual_Income, но это особенности его распределения и удалять их нельзя
    6. При анализе распределений категориаьных признаков, следует вывод о том, что в основном все признаки распределены почти равномерно, кроме кол-ва предыдущих обращений (Previous_Claims) - здесь много тех кто обращался 0-2 раза, и очень мало остальных. Также анализировались боксплоты - зависимости категории от таргета у признаков нет, кроме вышеупомянутой Previous_Claims
    7. При анализе признаков с датой, следует вывод что впринципе нет какой-то сезонности, все стабильно в течении года. Единственное есть увеличение таргета в определенные месяца (с апреля по сентябрь) с 1100 до 1115.
    8. Препроцессинг:
         - Для бинарных и порядковых признаков (Gender, Smoking Status,Exercise Frequency) → Ordinal Encoding.
         - Для номинальных признаков (Marital Status, Education Level, Occupation, Location, Policy Type, Customer Feedback, Property Type) → One-Hot Encoding
         - Численные признаки масштабируются с помощью StandartScaler
         - Пропуски заменяются медианным значением для численных и отдельной категорий для категориальных
    
- Baseline: Какие модели строились, какие результаты по метрикам? Какие важности у фич для разных моделей?
  Обучались следующие модели: Decision Tree (RMSE: 921.827, RMSLE: 1.0507), Random Forest (RMSE: 928.63, RMSLE: 1.0616), XGBoost(RMSE: 927.22, RMSLE: 1.0533), LightGBM(RMSE: 926.76, RMSLE: 1.0527).
  По важностям:
     - сравнивая Decision Tree и Random Forest: Обе модели, наиболее важными признаками выделяют Годовой доход, кредитный рейтинг, показатель здоровья и кол-во предыдущих страховых случаев. Random Forest имеет более концентрированное распределение важности на топ-3 признака, а Decision Tree показывает более равномерное распределение среди большего их числа
     - сравнивая бустинги: XGBoost предполагает сильную связь между доходом и таргетом, а для LightGBM наиболее важный признак - год заключения сделки. Остальные признаки по важности примерно схожи - кредитный рейтинг и рейтинг здоровья и кол-во предыдущих обращений
  
- Improvements: какие преобразования применялись? Какие дали прирост метрик и на сколько? Какие нет? чем это можно объяснить?
    - 1. При анализе числовых признаков, Annual_Income т.е. доход клиента оказался сильно ассиметричным. Попробуем перевести его в категориальный, произведя бинаризацию.
    - 2. Аналогичное преобразования для признака Health_Score (показатель здоровья)
    - 3. Два новых признака взаимодействий - между возрастом и рейтингом здоровья , возрастом автомобиля клиента и кол-вом предыдущих обращений.
    - 4. Признак взаимодействия - здоровья и предыдущих страховых случаев
    Первые два подхода позволили незначительно снизить RMSE, остальные два - не сделали лучше, но и не сделали хуже. Решил оставить все, может дадут какой то вклад при подборе гипер-ов. Тут скорее всего виновата синтетическая природа данных, распределения признаков очень нереалистичны, тяжело подобрать нужные нелинейные зависимости.
     Итого выбрал модель XGBoost для дальнейших улучшений и изменения его метрик после добавления признаков составило: -1.87 RMSE, -0.003 RMSLE
- Гиперпараметры: какой метод тюнинга использовался? Какие интервалы перебора? Какие оптимальные значения получились? Какой прирост это дало?
     - GridSearchCV:
           - {'XGBRegressor__colsample_bytree': 0.7,
 'XGBRegressor__learning_rate': 0.05,
 'XGBRegressor__max_depth': 3,
 'XGBRegressor__n_estimators': 40,
 'XGBRegressor__reg_alpha': 0}
     - BayesSearchCV:Лучшие параметры: OrderedDict({'colsample_bytree': 0.9792876191616846, 'gamma': 0.25921536534894757, 'learning_rate': 0.019916897658845245, 'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 239, 'reg_alpha': 4.689724822881251e-06, 'reg_lambda': 0.0003090459774731997, 'subsample': 0.7501184848121732})

   - тут первый подход не дал вообще никаких  улучшений, а с помощью второго метрики немного снизились (- 2.7 в RMSE и -0.003 в RMSLE)
